{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb598497",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enable reloading\n",
    "%load_ext autoreload\n",
    "# all the modules should be reloaded before executing the code\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d645231",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from pathlib import Path\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage, ToolMessage, filter_messages\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langgraph.graph import END, START, StateGraph\n",
    "from langgraph.types import Command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4a06c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Research Agent Subgraph.\"\"\"\n",
    "try:\n",
    "    from .configuration import Configuration\n",
    "    from .prompts import COMPRESS_RESEARCH_SIMPLE_HUMAN_MESSAGE, COMPRESS_RESEARCH_SYSTEM_PROMPT\n",
    "    from .states import ResearcherOutputState, ResearchState\n",
    "    from .utils import execute_tool_safely, get_all_tools, openai_websearch_called\n",
    "except ImportError:\n",
    "    import rootutils\n",
    "\n",
    "    rootutils.setup_root(search_from=str(Path.cwd().parent), indicator=[\".git\", \"pyproject.toml\"], pythonpath=True)\n",
    "    from src.agent.configuration import Configuration\n",
    "    from src.agent.prompts import COMPRESS_RESEARCH_SIMPLE_HUMAN_MESSAGE, COMPRESS_RESEARCH_SYSTEM_PROMPT\n",
    "    from src.agent.states import ResearcherOutputState, ResearchState\n",
    "    from src.agent.utils import execute_tool_safely, get_all_tools, openai_websearch_called"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114291ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a configurable model that we will use throughout the agent\n",
    "configurable_model = init_chat_model(\n",
    "    configurable_fields=(\"model\", \"max_tokens\", \"api_key\"),\n",
    ")\n",
    "\n",
    "\n",
    "async def research_agent(state: ResearchState, config: RunnableConfig):\n",
    "    config = Configuration.from_runnable_config(config)\n",
    "    research_msgs = state.get(\"research_messages\", [])\n",
    "    tools = await get_all_tools(config)\n",
    "\n",
    "    if len(tools) <= 1:  # ResearchComplete is default tool in the list\n",
    "        msg = \"No tools found to conduct research, please configure Search API\"\n",
    "        raise ValueError(msg)\n",
    "\n",
    "    research_model_config = {\n",
    "        \"model\": config.research_model,\n",
    "        \"max_tokens\": config.research_model_max_tokens,\n",
    "        # \"api_key\": config.research_model_api_key,\n",
    "        \"tags\": [\"langsmith:nostream\"],\n",
    "    }\n",
    "\n",
    "    research_model = (\n",
    "        configurable_model.bind_tools(\n",
    "            tools,\n",
    "        )\n",
    "        .with_retry(stop_after_attempt=config.max_structured_output_retries)\n",
    "        .with_config(research_model_config)\n",
    "    )\n",
    "\n",
    "    response = await research_model.ainvoke(\n",
    "        research_msgs,\n",
    "    )\n",
    "\n",
    "    return Command(\n",
    "        goto=\"research_tools\",\n",
    "        update={\n",
    "            \"research_messages\": [response],\n",
    "            \"tool_call_iterations\": state.get(\"tool_call_iterations\", 0) + 1,\n",
    "        },\n",
    "    )\n",
    "\n",
    "\n",
    "async def research_tools(state: ResearchState, config: RunnableConfig):\n",
    "    config = Configuration.from_runnable_config(config)\n",
    "    research_msgs = state.get(\"research_messages\", [])\n",
    "    most_recent_message = research_msgs[-1]\n",
    "\n",
    "    # Early exit Criteria: No tools calls (or native web search calls) were made by the researcher\n",
    "    if not most_recent_message.tool_calls and not openai_websearch_called(most_recent_message):\n",
    "        return Command(goto=\"compress_research\")\n",
    "\n",
    "    # Otherwise, execute tools and gather results\n",
    "    tools = await get_all_tools(config)\n",
    "\n",
    "    tools_by_name = {tool.name if hasattr(tool, \"name\") else tool.get(\"name\", \"web_search\"): tool for tool in tools}\n",
    "\n",
    "    tool_calls = most_recent_message.tool_calls\n",
    "\n",
    "    async_responses = [\n",
    "        execute_tool_safely(tools_by_name[tool_call[\"name\"]], tool_call[\"args\"], config) for tool_call in tool_calls\n",
    "    ]\n",
    "    observations = await asyncio.gather(*async_responses)\n",
    "    tool_outputs = [\n",
    "        ToolMessage(\n",
    "            content=observation,\n",
    "            name=tool_call[\"name\"],\n",
    "            tool_call_id=tool_call[\"id\"],\n",
    "        )\n",
    "        for observation, tool_call in zip(observations, tool_calls, strict=False)\n",
    "    ]\n",
    "    # Late Exit Criteria: We have exceeded our max guardrail tool call iterations or the most recent message contains ResearchComplete tool call\n",
    "    # These are late exit criteria because we need to add ToolMessage\n",
    "    update = {\"research_messages\": tool_outputs}\n",
    "    if state.get(\"tool_call_iterations\", 0) >= config.max_react_tool_calls or any(\n",
    "        tool_call[\"name\"] == \"ResearchComplete\" for tool_call in tool_calls\n",
    "    ):\n",
    "        return Command(\n",
    "            goto=\"compress_research\",\n",
    "            update=update,\n",
    "        )\n",
    "    return Command(goto=\"research_agent\", update=update)\n",
    "\n",
    "\n",
    "async def compress_research(state: ResearchState, config: RunnableConfig):\n",
    "    config = Configuration.from_runnable_config(config)\n",
    "    synthesize_attempts = 0\n",
    "    compression_model = configurable_model.with_config(\n",
    "        {\n",
    "            \"model\": config.compression_model,\n",
    "            \"max_tokens\": config.compression_model_max_tokens,\n",
    "            # \"api_key\": config.compress_model_api_key,\n",
    "        },\n",
    "    )\n",
    "    researcher_msgs = state.get(\"research_messages\", [])\n",
    "\n",
    "    # Update the system prompts to now focus on compression rather than research\n",
    "    researcher_msgs[0] = SystemMessage(\n",
    "        content=COMPRESS_RESEARCH_SYSTEM_PROMPT,\n",
    "    )\n",
    "    researcher_msgs.append(HumanMessage(content=COMPRESS_RESEARCH_SIMPLE_HUMAN_MESSAGE))\n",
    "    while synthesize_attempts < config.compression_attempts:\n",
    "        try:\n",
    "            response = await compression_model.ainvoke(\n",
    "                researcher_msgs,\n",
    "            )\n",
    "            return {\n",
    "                \"compressed_research\": str(response.content),\n",
    "                \"raw_notes\": [\n",
    "                    \"\\n\".join(\n",
    "                        [str(m.content) for m in filter_messages(researcher_msgs, include_types=[\"tool\", \"ai\"])],\n",
    "                    ),\n",
    "                ],\n",
    "            }\n",
    "        except Exception as e:\n",
    "            # import traceback\n",
    "\n",
    "            # print(e, traceback.format_exc())\n",
    "            synthesize_attempts += 1\n",
    "            # TODO(@viv): #123 Add token limit check\n",
    "            # if is_token_limit_exceeded(e, configurable.research_model):\n",
    "            #     researcher_msgs = remove_up_to_last_ai_message(researcher_msgs)\n",
    "            #     print(f\"Token limit exceeded while synthesizing: {e}. Pruning the messages to try again.\")\n",
    "            #     continue\n",
    "            print(f\"Error synthesizing research report: {e}\")\n",
    "    return {\n",
    "        \"compressed_research\": \"Error synthesizing research report: Maximum retries exceeded\",\n",
    "        \"raw_notes\": [\n",
    "            \"\\n\".join([str(m.content) for m in filter_messages(researcher_msgs, include_types=[\"tool\", \"ai\"])]),\n",
    "        ],\n",
    "    }\n",
    "\n",
    "\n",
    "research_builder = StateGraph(ResearchState, output_schema=ResearcherOutputState, config_schema=Configuration)\n",
    "research_builder.add_node(\"research_agent\", research_agent)\n",
    "research_builder.add_node(\"compress_research\", compress_research)\n",
    "research_builder.add_node(\"research_tools\", research_tools)\n",
    "\n",
    "research_builder.add_edge(START, \"research_agent\")\n",
    "research_builder.add_edge(\"compress_research\", END)\n",
    "researcher_graph = research_builder.compile(name=\"Research Agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bab0ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = [\n",
    "    #  HumanMessage(content=PROJECT_IDEA),\n",
    "    AIMessage(\"\"\" 1. **Target Audience and Purpose:**\n",
    "   - You mentioned this is a personal project for fun and learning, as well as to showcase your skills to potential interviewers. Is there a specific aspect of the project you want to highlight to interviewers (e.g., AI capabilities, UI design, integration skills)?\n",
    "2. **Image Processing:**\n",
    "   - For the feature that takes pictures of handwritten notes, do you have any specific requirements or preferences for the image capture process (e.g., camera integration, file upload)?\n",
    "   - Are there any particular challenges you anticipate with processing equations and block diagrams, and do you have any existing tools or libraries in mind to handle these?\n",
    "3. **Integration with Notion:**\n",
    "   - Could you elaborate on how you envision the integration with Notion? For example, do you have a specific structure or organization in mind for the notes within Notion?\n",
    "   - Are there any specific Notion API functionalities you plan to use or any constraints you are aware of?\n",
    "4. **LangGraph and UI:**\n",
    "   - You mentioned using LangGraph's prebuilt UI. Could you provide more details on how you plan to utilize it? Are there any customizations or additional features you want to add to the UI?\n",
    "5. **Multi-Agent System:**\n",
    "   - You are considering a multi-agent system. Could you describe how you envision the interaction between the agents, and what specific roles each agent will play?\n",
    "6. **MVP and Timeline:**\n",
    "   - For the MVP, you aim to convert images to text and format them properly within two weeks. Are there any specific milestones or deliverables you have in mind for this initial phase?\n",
    "7. **Future Development:**\n",
    "   - You mentioned the possibility of developing a simple Android app using Flutter later on. Do you have any specific features or functionalities in mind for the mobile version?\n",
    " \"\"\"),\n",
    "    HumanMessage(\n",
    "        content=\"\"\"\n",
    "1. nothing specific, but good working app, because i am going to use it regularly\n",
    "2. for the time being we can go with file upload and when i decide to make android app using flutter then we can integrate images directly from the camera\n",
    "3. I am thinking to fetch all the pages and sub pages and find pages with name and create a sub page and add notes over there. for example if topic is about optimizer then i will find page with deep learning and create a new sub page and add notes over there.\n",
    "4. No, first i want to use only langgraph UI, it is really nice and easy to use\n",
    "5. I am also thinking to use multi agent system one agent for image to text conversion and 2nd agent for text to notion or formatting (markdown)\n",
    "6. no nothing specific milestone or anything\n",
    "7. no just simple camera app with little instruction/chat box for Agent if needed\n",
    "\"\"\",\n",
    "    ),\n",
    "    AIMessage(\"\"\"1. **App Usage and Quality:**\n",
    "   - You want a reliable and well-functioning app since you'll be using it regularly. Are there any specific performance or usability criteria you have in mind to ensure it meets your needs?\n",
    "2. **Image Capture and Processing:**\n",
    "   - For now, you prefer to start with a file upload feature for images. When you transition to an Android app using Flutter, do you have any specific requirements for how the camera integration should work?\n",
    "3. **Notion Integration:**\n",
    "   - You plan to fetch pages and sub-pages in Notion, find specific pages by name, and create sub-pages to add notes. Could you clarify if you have a specific naming convention or criteria for identifying these pages?\n",
    "   - How do you envision the notes being structured or formatted once they are added to Notion?\n",
    "4. **LangGraph UI:**\n",
    "   - You are satisfied with using LangGraph's UI as it is. Are there any specific features or interactions within the UI that are crucial for your workflow?\n",
    "5. **Multi-Agent System:**\n",
    "   - You plan to use one agent for image-to-text conversion and another for text formatting and integration with Notion. Could you describe any specific interactions or data flow between these agents?\n",
    "6. **Milestones and Timeline:**\n",
    "   - While you don't have specific milestones, do you have a rough timeline or order of priorities for implementing different features?\n",
    "7. **Future Android App:**\n",
    "   - For the future Android app, you mentioned a simple camera app with a chat box for agent instructions. Are there any additional features or user interactions you envision for this app?\n",
    "Please let me know if there are any other aspects of the project you'd like to discuss or clarify further.\n",
    " \"\"\"),\n",
    "    HumanMessage(\n",
    "        content=\"1. no, i have not thought about it yet, we can check after first MVP is done\"\n",
    "        \"2.i will use langgraph UI to upload the images for the time being\"\n",
    "        \"3. simple chat ui with upload image button and text input box\"\n",
    "        \"4. No not yet, because i have not use it. i will see once we reach to that point\"\n",
    "        \"5. first agent will convert image to text and send this text information to 2nd agent and 2nd agent will format it and send it to notion\"\n",
    "        \"6. no milestone or anything\"\n",
    "        \"7.no nothing\",\n",
    "    ),\n",
    "]\n",
    "PROJECT_IDEA = (\n",
    "    \"create plan to develop Agentic AI note taking app using langgraph for my personal use (personal project for fun and learning) and i also want to show off my skills to my potential interviewer to get hired. it should do following \"\n",
    "    \"1. take pictures of hand-written notes \"\n",
    "    \"2. it will automatically format the hand-written notes (it might contains equations and block diagrams) \"\n",
    "    \"3. find proper section (if section found then create sub page or create a new page) in my notion \"\n",
    "    \"4. add this notes with proper format\"\n",
    "    \"5. i want to use LangGraph's pre-build UI for interaction from PC\"\n",
    "    \"6. for MVP (which can convert image to text and format it properly) in 2 weeks\"\n",
    "    \"7. I am also thinking to use multi agent system one agent for image to text conversion and 2nd agent for text to notion or formatting (markdown)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee202300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# async for event in researcher_graph.astream(\n",
    "#     {\n",
    "#         \"research_messages\": [*conversation, HumanMessage(content=research_brief)],\n",
    "#         #   \"research_brief\": research_brief,\n",
    "#         \"research_topic\": PROJECT_IDEA,\n",
    "#     },\n",
    "#     stream_mode=\"update\",\n",
    "# ):\n",
    "#     print(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2440d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project-planning-genie",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
